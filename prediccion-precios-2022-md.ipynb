{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicción Precios Argentina - MD 2022\n",
        "\n",
        "Notebook para la competencias de [Kaggle](https://www.kaggle.com/competitions/fcen-md-2022-prediccion-precio-de-propiedades/leaderboard) de la materia MD de la maestria de DM de la UBA.\n",
        "\n",
        "Autor: Tomás Delvechio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuración de la notebook\n",
        "\n",
        "A continuación se definen configuraciones que afectaran el resto del notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "EJECUTA_COLAB = 'google.colab' in sys.modules\n",
        "#DATASET_RAW_LOCAL_NAME = 'ar_properties.csv'\n",
        "#DATASET_COMPRESSED_LOCAL_NAME = DATASET_RAW_LOCAL_NAME + '.gz'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datasets\n",
        "\n",
        "Se listan todos los datasets a considerar a continuación en un dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = {\n",
        "\n",
        "    \"input\": {\n",
        "\n",
        "        # Dataset de entrenamiento\n",
        "        \"entrenamiento\": {\n",
        "            \"nombre\": \"properati_ar\",\n",
        "            \"archivo\": 'ar_properties.csv',\n",
        "            \"archivo_comprimido\": \"ar_properties.csv.gz\",\n",
        "            \"comprimido\": \"gz\",\n",
        "            \"url\": \"https://storage.googleapis.com/properati-data-public/ar_properties.csv.gz\",\n",
        "        },\n",
        "\n",
        "        # Dataset de prueba\n",
        "        \"prueba\": {\n",
        "            \"nombre\": \"testing\",\n",
        "            \"archivo\": \"a_predecir.csv\",\n",
        "            \"archivo_comprimido\": \"a_predecir.csv.zip\",\n",
        "            \"comprimido\": \"zip\",\n",
        "            \"url\": \"http://tomasdelvechio.github.io/subjects/dm/a_predecir.csv.zip\",\n",
        "        },\n",
        "\n",
        "    },\n",
        "\n",
        "    \"output\": {\n",
        "\n",
        "        # Dataset para subir a Kaggle\n",
        "        \"solucion\": {\n",
        "            \"nombre\": \"soluciones\",\n",
        "            \"archivo\": \"solucion.csv\",\n",
        "            \"comprimido\": False,\n",
        "            \"url\": None,\n",
        "        },\n",
        "\n",
        "    },\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Descarga de los datasets\n",
        "\n",
        "Controla si los datasets estan o no descargado, en caso de no estarlo, los descarga y descomprime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "A7BBykw5oQNl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando ds para entrenamiento: properati_ar\n",
            "Dataset properati_ar descargado... No se descarga...\n",
            "Procesando ds para prueba: testing\n",
            "Dataset testing descargado... No se descarga...\n"
          ]
        }
      ],
      "source": [
        "if EJECUTA_COLAB:\n",
        "    DOWNLOAD_PATH = '/content'\n",
        "else:\n",
        "    DOWNLOAD_PATH = '.data/'\n",
        "    # tratamos de crear el dir por si es la 1era vez que ejecuta\n",
        "    ! mkdir -p $DOWNLOAD_PATH\n",
        "\n",
        "for tipo, ds in datasets[\"input\"].items():\n",
        "    print(f\"Procesando ds para {tipo}: {ds['nombre']}\")\n",
        "\n",
        "    fulllpath = os.path.join(\n",
        "        DOWNLOAD_PATH, f\"{ds['archivo_comprimido']}\")\n",
        "    fulllpath_raw = os.path.join(\n",
        "        DOWNLOAD_PATH, ds[\"archivo\"])\n",
        "\n",
        "    if os.path.exists(fulllpath_raw):\n",
        "        # skip download\n",
        "        print(f\"Dataset {ds['nombre']} descargado... No se descarga...\")\n",
        "    else:\n",
        "        url = ds[\"url\"]\n",
        "        print(f\"Descargando {ds['nombre']} desde {url}\")\n",
        "        ! wget -N -O $fulllpath -q $url\n",
        "        if ds[\"comprimido\"] == \"gz\":\n",
        "            ! gzip -d -f $fulllpath\n",
        "        elif ds[\"comprimido\"] == \"zip\":\n",
        "            ! unzip -n $fulllpath -d \".data/\"\n",
        "            ! rm $fulllpath\n",
        "\n",
        "archivo_entrenamiento = os.path.join(\n",
        "    DOWNLOAD_PATH, datasets[\"input\"][\"entrenamiento\"][\"archivo\"])\n",
        "archivo_prueba = os.path.join(\n",
        "    DOWNLOAD_PATH, datasets[\"input\"][\"prueba\"][\"archivo\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Importación de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jw8ogMDOpvKP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn import model_selection\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20D-m6GPyefp"
      },
      "source": [
        "# Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CtV0wOGsqJLC"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento_inicial = pd.read_csv(archivo_entrenamiento, index_col=\"id\")\n",
        "df_prueba_inicial = pd.read_csv(archivo_prueba, index_col=\"id\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ckXCv9f-uia0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17972, 24)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# filtro para pruebas rápidas\n",
        "df = df.loc[(df.l2 == \"Córdoba\") & (df.operation_type == 'Venta') & (df.property_type == 'Casa')]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byV0dQi-yiEd"
      },
      "source": [
        "# Análisis del conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjaTnfxkyvo8"
      },
      "source": [
        "# Tratamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2jRJmQ-tD4Z"
      },
      "source": [
        "# Modelización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yg8qNxuNrzQp"
      },
      "outputs": [],
      "source": [
        "df = df.select_dtypes(include=['float64', 'int64'])\n",
        "df.fillna(0, inplace=True, downcast= \"infer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PoAhfAjlr-rp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimators=100, max_depth=3 --> 1092877.244 +/- 326348.764\n",
            "n_estimators=100, max_depth=7 --> 1091396.303 +/- 303108.089\n",
            "n_estimators=100, max_depth=11 --> 1057311.935 +/- 261268.926\n",
            "n_estimators=500, max_depth=3 --> 1093316.561 +/- 326591.421\n",
            "n_estimators=500, max_depth=7 --> 1090799.671 +/- 303480.374\n",
            "n_estimators=500, max_depth=11 --> 1054131.309 +/- 261351.210\n",
            "n_estimators=1000, max_depth=3 --> 1093700.609 +/- 326763.124\n",
            "n_estimators=1000, max_depth=7 --> 1089087.818 +/- 300652.070\n",
            "n_estimators=1000, max_depth=11 --> 1053844.945 +/- 261281.861\n"
          ]
        }
      ],
      "source": [
        "X = df[df.columns.drop('price')]\n",
        "y = df['price']\n",
        "\n",
        "for n_estimators in [100, 500, 1000]:     \n",
        "    for max_depth in [3, 7, 11]:\n",
        "\n",
        "        ## Tienen que usar RandomForestRegressor si o si o si. Pueden cambiar los parámetros\n",
        "        reg = sk.ensemble.RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
        "\n",
        "        ## Validación cruzada en 5 partes (lo van a ver en AA), -RMSE. No tocar\n",
        "        scores = sk.model_selection.cross_val_score(reg, X, y, cv=10, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "        ## Imprimimos scores. Cuando más bajo mejor\n",
        "        print(f\"n_estimators={n_estimators}, max_depth={max_depth} --> {-scores.mean():.3f} +/- {scores.std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01697gx81F5Z"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.read_csv('/content/a_predecir.csv', index_col=\"id\")\n",
        "df_pred.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzAwUNRA1Fzb"
      },
      "outputs": [],
      "source": [
        "X_pred = df_pred[X.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81dOh5WvAPMa"
      },
      "outputs": [],
      "source": [
        "# los mejores hiperparámetros encontrados antes\n",
        "n_estimators = 100\n",
        "max_depth = 3\n",
        "\n",
        "# entrenamiento\n",
        "reg = sk.ensemble.RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
        "reg.fit(X, y)\n",
        "\n",
        "# predicción\n",
        "df_pred[\"price\"] = reg.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU9iV6cuBwKB"
      },
      "outputs": [],
      "source": [
        "# grabo la solución\n",
        "df_pred[[\"price\"]].to_csv(\"solucion.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copia de TP individual.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
